{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Pinecone as PineconeVectorStore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pinecone import Pinecone\n",
    "\n",
    "with open('../.env', 'r') as config_file:\n",
    "    config = json.loads(config_file.read())\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = config['OPENAI_API_KEY']\n",
    "os.environ['OPENAI_BASE_URL'] = config['OPENAI_BASE_URL']\n",
    "os.environ['OPENAI_API_BASE'] = config['OPENAI_BASE_URL']\n",
    "os.environ['DEFAULT_MODEL'] = config['DEFAULT_MODEL']\n",
    "os.environ['PINECONE_API_KEY'] = config['PINECONE_API_KEY']\n",
    "model = os.environ['DEFAULT_MODEL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busca Semântica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_path = 'documentos.zip'\n",
    "extracted_folder_path = 'docs'\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)\n",
    "\n",
    "documents = []\n",
    "for filename in os.listdir(extracted_folder_path):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(extracted_folder_path, filename)\n",
    "        loader = PyMuPDFLoader(file_path)\n",
    "        documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  \n",
    "    chunk_overlap=100,\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.create_documents([doc.page_content for doc in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'llm' \n",
    "vector_store = PineconeVectorStore.from_documents(chunks, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = '''Responda apenas com base no input fornecido. Qual o número do processo que trata de Violação\n",
    "de normas ambientais pela Empresa de Construção?'''\n",
    "query_2 = 'Responda apenas com base no input fornecido. Qual foi a decisão no caso de fraude financeira?'\n",
    "query_3 = 'Responda apenas com base no input fornecido. Quais foram as alegações no caso de negligência médica?'\n",
    "query_4 = 'Responda apenas com base no input fornecido. Quais foram as alegações no caso de Número do Processo: 822162' #disputa contratual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=model, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_1 = chain.invoke(query_1)\n",
    "answer_2 = chain.invoke(query_2)\n",
    "answer_3 = chain.invoke(query_3)\n",
    "answer_4 = chain.invoke(query_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pergunta: ', answer_1['query'])\n",
    "print('Resultado: ', answer_1['result'],'\\n')\n",
    "#---\n",
    "print('Pergunta: ', answer_2['query'])\n",
    "print('Resultado: ', answer_2['result'],'\\n')\n",
    "#---\n",
    "print('Pergunta: ', answer_3['query'])\n",
    "print('Resultado: ', answer_3['result'],'\\n')\n",
    "#---\n",
    "print('Pergunta: ', answer_4['query'])\n",
    "print('Resultado: ', answer_4['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
